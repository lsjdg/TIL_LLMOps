{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets==2.21.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (2.21.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (0.25.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from datasets==2.21.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from aiohttp->datasets==2.21.0) (1.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests>=2.32.2->datasets==2.21.0) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from pandas->datasets==2.21.0) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from pandas->datasets==2.21.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from pandas->datasets==2.21.0) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.21.0) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers datasets==2.21.0 scipy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "task = \"ynat\"  # Yahoo News Article Topic Classification\n",
    "datasets = load_dataset(\"klue\", task)  # Korean Language Understanding Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "        num_rows: 45678\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "        num_rows: 9107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'ynat-v1_train_00000',\n",
       " 'title': 'ìœ íŠœë¸Œ ë‚´ë‹¬ 2ì¼ê¹Œì§€ í¬ë¦¬ì—ì´í„° ì§€ì› ê³µê°„ ìš´ì˜',\n",
       " 'label': 3,\n",
       " 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n",
       " 'date': '2016.06.30. ì˜¤ì „ 10:36'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from datasets import ClassLabel\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(\n",
    "        dataset\n",
    "    ), \"Can't pick more elements than there are in the dataset.\"\n",
    "\n",
    "    picks = []\n",
    "\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        # ì´ë¯¸ ë“±ë¡ëœ ì˜ˆì œê°€ ë½‘íŒ ê²½ìš°, ë‹¤ì‹œ ì¶”ì¶œ\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "\n",
    "        picks.append(pick)\n",
    "\n",
    "    # ì„ì˜ë¡œ ì¶”ì¶œëœ ì¸ë±ìŠ¤ë“¤ë¡œ êµ¬ì„±ëœ ë°ì´í„° í”„ë ˆì„ ì„ ì–¸\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "\n",
    "    for column, typ in dataset.features.items():\n",
    "        # ë¼ë²¨ í´ë˜ìŠ¤ë¥¼ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ë³€í™˜\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_16018</td>\n",
       "      <td>ä¸­ ì§€ë‚œë‹¬ ì°¨ì´ì‹  ì œì¡°ì—… PMI 49.7â€¦1ë…„ë°˜ë§Œì— ê²½ê¸°ìœ„ì¶• ì§„ì…ì¢…í•©</td>\n",
       "      <td>ì„¸ê³„</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=104&amp;sid2=231&amp;oid=001&amp;aid=0010557853</td>\n",
       "      <td>2019.01.02. ì˜¤ì „ 11:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_14558</td>\n",
       "      <td>ì‹ ê°„ ë§ˆë¸”ì´ ì„¤ê³„í•œ ì‚¬ì†Œí•˜ê³  ìœ„ëŒ€í•œ ê³¼í•™</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=103&amp;sid2=243&amp;oid=001&amp;aid=0011195712</td>\n",
       "      <td>2019.11.07. ì˜¤ì „ 10:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_41528</td>\n",
       "      <td>1ë³´ ì½”ìŠ¤í”¼ ì—¿ìƒˆì§¸ í•˜ë½ 1910ì„  ë‚´ì¤˜â€¦ì½”ìŠ¤ë‹¥ì€ 2%ëŒ€ ìƒìŠ¹</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=101&amp;sid2=258&amp;oid=001&amp;aid=0011007136</td>\n",
       "      <td>2019.08.07. ì˜¤í›„ 3:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_44837</td>\n",
       "      <td>ê·¸ë˜í”½ ì§€ë‚œí•´ 51ì±„ ì´ìƒ ì§‘ë¶€ì 1988ëª…</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=101&amp;sid2=263&amp;oid=001&amp;aid=0010542037</td>\n",
       "      <td>2018.12.23. ì˜¤í›„ 4:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_18671</td>\n",
       "      <td>ì‹ ê°„ ê±°ì§“ë§ ì½ëŠ” ë²•Â·ì‚¬ëŒì˜ ìë¦¬ ê³¼í•™ì˜ ë§ˆìŒì— ë‹¿ë‹¤</td>\n",
       "      <td>ìƒí™œë¬¸í™”</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=103&amp;sid2=243&amp;oid=001&amp;aid=0010773097</td>\n",
       "      <td>2019.04.19. ì˜¤ì „ 7:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ynat-v1_train_00507</td>\n",
       "      <td>ì…°í¬ë¨¼ í˜¸ê¸°ì‹¬ ë¶„ì•¼ ê¾¸ì¤€í•œ ì—°êµ¬ê°€ ë…¸ë²¨ìƒ ë¹„ê²°</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=105&amp;sid2=228&amp;oid=001&amp;aid=0008729806</td>\n",
       "      <td>2016.10.05. ì˜¤í›„ 2:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ynat-v1_train_09046</td>\n",
       "      <td>IoTë¡œ ì“°ë ˆê¸°í†µ ê´€ë¦¬í•´ìš”</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=105&amp;sid2=227&amp;oid=001&amp;aid=0009270846</td>\n",
       "      <td>2017.05.17. ì˜¤ì „ 10:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ynat-v1_train_42212</td>\n",
       "      <td>ê¸ˆì„±í…Œí¬ ì§€ì—ìŠ¤ì•ŒíŒŒíŠ¸ë„ˆìŠ¤ì— ì˜í•´ íŒŒì‚°ì‹ ì²­â€¦ê±°ë˜ ì •ì§€</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=101&amp;sid2=261&amp;oid=001&amp;aid=0008501668</td>\n",
       "      <td>2016.06.27. ì˜¤í›„ 5:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ynat-v1_train_42518</td>\n",
       "      <td>ê²Œì‹œíŒ ì‹ í•œê¸ˆìœµ ê¸°í›„ë³€í™” ëŒ€ì‘ ìµœìš°ìˆ˜ê¸°ì—…ìœ¼ë¡œ ëª…ì˜ˆì˜ ì „ë‹¹ ì…ì„±</td>\n",
       "      <td>ê²½ì œ</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=101&amp;sid2=259&amp;oid=001&amp;aid=0010783342</td>\n",
       "      <td>2019.04.24. ì˜¤ì „ 11:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ynat-v1_train_35631</td>\n",
       "      <td>ì¹´í†¡ ì´ëª¨í‹°ì½˜ ì¹´ì¹´ì˜¤ TVÂ·ë‹¤ìŒ í¬í„¸ì—ì„œë„ ì“´ë‹¤</td>\n",
       "      <td>ITê³¼í•™</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D&amp;mid=shm&amp;sid1=105&amp;sid2=227&amp;oid=001&amp;aid=0009198040</td>\n",
       "      <td>2017.04.18. ì˜¤í›„ 2:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KLUE TC**\n",
    "\n",
    "- 0 (ITê³¼í•™)\n",
    "- 1 (ê²½ì œ)\n",
    "- 2 (ì‚¬íšŒ)\n",
    "- 3 (ìƒí™œë¬¸í™”)\n",
    "- 4 (ì„¸ê³„)\n",
    "- 5 (ìŠ¤í¬ì¸ )\n",
    "- 6 (ì •ì¹˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h0/f86w2r851zn7yj1w80yw932h0000gn/T/ipykernel_21753/3905583055.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"f1\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"f1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1]),\n",
       " array([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = np.random.randint(0, 2, size=(64,))\n",
    "fake_labels = np.random.randint(0, 2, size=(64,))\n",
    "\n",
    "fake_preds, fake_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.6666666666666666}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(\n",
    "    predictions=fake_preds,  # ì˜ˆì¸¡ ê°’\n",
    "    references=fake_labels,  # target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ NLUë¥¼ ìœ„í•œ ëŒ€í‘œì ì¸ ëª¨ë¸\n",
    "model_name = \"klue/roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ì—ì„œ í™œì•½í•  ì†í¥ë¯¼ ì„ ìˆ˜ì˜ ë§ˆì§€ë§‰ í•œêµ­ ì¸í„°ë·°\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 12416, 4469, 27135, 5943, 2085, 11251, 3825, 2079, 4178, 3629, 5111, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='klue/roberta-base', vocab_size=32000, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(\n",
    "        data[\"title\"],  # ë°ì´í„°\n",
    "        truncation=True,  # ë¬¸ì¥ì´ ëª¨ë¸ì´ ë°›ì•„ë“¤ì¼ ìˆ˜ ìˆëŠ” ìµœëŒ€ ê¸¸ì´ ì´ìƒìœ¼ë¡œ ë“¤ì–´ì˜¬ ê²½ìš° ìµœëŒ€ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‹œí€€ìŠ¤(ë¬¸ì¥) ìë¥´ê¸°\n",
    "        return_token_type_ids=False,  # token_type_idsê°€ í•„ìš”ì—†ëŠ” RoBERTa ëª¨ë¸ì€ Falseë¡œ ì„¤ì •\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 10637, 8474, 22, 2210, 2299, 2118, 28940, 3691, 4101, 3792, 2], [0, 24905, 1042, 4795, 19982, 2129, 121, 6904, 16311, 3, 14392, 2], [0, 4172, 3797, 3728, 2107, 2134, 3777, 904, 6022, 2332, 2113, 2259, 4523, 1380, 2259, 2062, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(datasets[\"train\"][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ì „ì²˜ë¦¬ ì ìš©\n",
    "encoded_datasets = datasets.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 7\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ì´ ì˜ˆì¸¡ í–ˆì„ ë•Œ ì§€í‘œ ê³„ì‚°\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer ì •ì˜\n",
    "ì´ì œ ì•ì„œ ì •ì˜í•œ ì •ë³´ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ `transformers`ì—ì„œ ì œê³µí•˜ëŠ” *Trainer* ê°ì²´ë¥¼ í™œìš©í•˜ê¸° ìœ„í•œ ì¸ì ê´€ë¦¬ í´ë˜ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "`metric_name`ì€ ì•ì„œ ì–»ì–´ì§„ ë©”íŠ¸ë¦­ í•¨ìˆ˜ë¥¼ í™œìš©í–ˆì„ ë•Œ, ì•„ë˜ì™€ ê°™ì´ `dict` í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ ê°’ì´ ë°˜í™˜ë˜ëŠ”ë° ì—¬ê¸°ì„œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  *key* ë¥¼ ì •ì˜í•´ì¤€ë‹¤ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    ">>> metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "{'f1': 0.85}\n",
    "```\n",
    "\n",
    "ê° ì¸ìì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ [ë¬¸ì„œ](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)ì—ì„œ ì°¸ì¡°í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: transformers[torch] in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from transformers[torch]) (2.4.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from torch->transformers[torch]) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from torch->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from jinja2->torch->transformers[torch]) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/llm-env/lib/python3.11/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"transformers[torch]\" \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm-env/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments,\n",
    ")  # Trainer í´ë˜ìŠ¤ì—ì„œ ì‚¬ìš©í•  í›ˆë ¨ìš© í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "\n",
    "metric_name = \"f1\"  # metric ê°ì²´ì™€ ë™ì¼í•œ ì§€í‘œë¥¼ ì‚¬ìš©\n",
    "batch_size = 32\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"../../data/saved_models/test-tc\",  # ëª¨ë¸ ê²°ê³¼ë¬¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬\n",
    "    evaluation_strategy=\"epoch\",  # í‰ê°€ ì „ëµ. ì–¸ì œ ë§ˆë‹¤ í‰ê°€ í• ì§€ë¥¼ ê²°ì •\n",
    "    save_strategy=\"epoch\",  # ëª¨ë¸ ì €ì¥ì€ ì–¸ì œë§ˆë‹¤ í• ê±´ì§€.\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534d3209aa2e4391ab8263b4048ab1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5628, 'grad_norm': 9.216388702392578, 'learning_rate': 1.8599439775910366e-05, 'epoch': 0.35}\n",
      "{'loss': 0.39, 'grad_norm': 6.487459182739258, 'learning_rate': 1.719887955182073e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a8c92e28204cbfa01361c12b416432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4037039279937744, 'eval_f1': 0.8606807733675929, 'eval_runtime': 33.5434, 'eval_samples_per_second': 271.499, 'eval_steps_per_second': 8.496, 'epoch': 1.0}\n",
      "{'loss': 0.3572, 'grad_norm': 5.403110980987549, 'learning_rate': 1.5798319327731094e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2895, 'grad_norm': 4.995489120483398, 'learning_rate': 1.4397759103641458e-05, 'epoch': 1.4}\n",
      "{'loss': 0.2948, 'grad_norm': 5.401579856872559, 'learning_rate': 1.2997198879551822e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e455ef6d0cd5475595cce21d8f7f5b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3689662516117096, 'eval_f1': 0.8666661157253167, 'eval_runtime': 37.3849, 'eval_samples_per_second': 243.601, 'eval_steps_per_second': 7.623, 'epoch': 2.0}\n",
      "{'loss': 0.2704, 'grad_norm': 4.673801898956299, 'learning_rate': 1.1596638655462186e-05, 'epoch': 2.1}\n",
      "{'loss': 0.2191, 'grad_norm': 7.442636489868164, 'learning_rate': 1.0196078431372549e-05, 'epoch': 2.45}\n",
      "{'loss': 0.2223, 'grad_norm': 4.694640159606934, 'learning_rate': 8.795518207282914e-06, 'epoch': 2.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15710afede284fca9ccd11e606529c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4027175009250641, 'eval_f1': 0.8651651509341871, 'eval_runtime': 27.7162, 'eval_samples_per_second': 328.58, 'eval_steps_per_second': 10.283, 'epoch': 3.0}\n",
      "{'loss': 0.2005, 'grad_norm': 7.577108383178711, 'learning_rate': 7.394957983193279e-06, 'epoch': 3.15}\n",
      "{'loss': 0.1614, 'grad_norm': 4.262217998504639, 'learning_rate': 5.994397759103642e-06, 'epoch': 3.5}\n",
      "{'loss': 0.1661, 'grad_norm': 8.207027435302734, 'learning_rate': 4.593837535014006e-06, 'epoch': 3.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ad1aef39c244fe8da135222bbf6042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45816242694854736, 'eval_f1': 0.864923492036132, 'eval_runtime': 34.8216, 'eval_samples_per_second': 261.533, 'eval_steps_per_second': 8.185, 'epoch': 4.0}\n",
      "{'loss': 0.1436, 'grad_norm': 7.979711055755615, 'learning_rate': 3.1932773109243696e-06, 'epoch': 4.2}\n",
      "{'loss': 0.1297, 'grad_norm': 3.0681309700012207, 'learning_rate': 1.792717086834734e-06, 'epoch': 4.55}\n",
      "{'loss': 0.1155, 'grad_norm': 12.434139251708984, 'learning_rate': 3.921568627450981e-07, 'epoch': 4.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b950e4ca7d441acbce2af13d52ada0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49951910972595215, 'eval_f1': 0.862966249587739, 'eval_runtime': 37.6398, 'eval_samples_per_second': 241.951, 'eval_steps_per_second': 7.572, 'epoch': 5.0}\n",
      "{'train_runtime': 5672.0255, 'train_samples_per_second': 40.266, 'train_steps_per_second': 1.259, 'train_loss': 0.24900020524567248, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7140, training_loss=0.24900020524567248, metrics={'train_runtime': 5672.0255, 'train_samples_per_second': 40.266, 'train_steps_per_second': 1.259, 'total_flos': 2555331086520900.0, 'train_loss': 0.24900020524567248, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer  # TrainingArgumentsë¥¼ ì…ë ¥ ë°›ì•„ í›ˆë ¨ì„ ìˆ˜í–‰\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,  # í›ˆë ¨ ì‹œí‚¬ ëª¨ë¸\n",
    "    args,  # TrainingArguments\n",
    "    train_dataset=encoded_datasets[\"train\"],\n",
    "    eval_dataset=encoded_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278018225da94cba8cc28945d8f82d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/285 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3689662516117096,\n",
       " 'eval_f1': 0.8666661157253167,\n",
       " 'eval_runtime': 39.7928,\n",
       " 'eval_samples_per_second': 228.86,\n",
       " 'eval_steps_per_second': 7.162,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ê°€ì¥ ì¢‹ì€ Metric ì„ ë³´ì¸ Model ì˜ checkpoint\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/opt/anaconda3/envs/llm-env/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"../../data/saved_models/test-tc/checkpoint-2856\",\n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ì—ì„œ í™œì•½í•  ì†í¥ë¯¼ ì„ ìˆ˜ì˜ ë§ˆì§€ë§‰ í•œêµ­ ì¸í„°ë·°\n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.004838953725993633},\n",
       "  {'label': 'LABEL_1', 'score': 0.0013362442841753364},\n",
       "  {'label': 'LABEL_2', 'score': 0.02681775577366352},\n",
       "  {'label': 'LABEL_3', 'score': 0.7445481419563293},\n",
       "  {'label': 'LABEL_4', 'score': 0.21785353124141693},\n",
       "  {'label': 'LABEL_5', 'score': 0.0016611474566161633},\n",
       "  {'label': 'LABEL_6', 'score': 0.002944271545857191}]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"ê¸°ì•ˆ 84ê°€ ê° ì§€ìŠ¤ ê°•ë¬¼ì„ ë§ˆì…¨ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
